{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "import required modules"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import random\n", "from tqdm.notebook import tqdm\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from sklearn.model_selection import train_test_split\n", "from sklearn import model_selection, metrics, preprocessing\n", "import copy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "from torch import nn, optim, Tensor"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from collections import defaultdict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from torch_geometric.utils import structured_negative_sampling\n", "from torch_geometric.data import download_url, extract_zip\n", "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n", "from torch_geometric.nn.conv import MessagePassing\n", "from torch_geometric.typing import Adj\n", "import torch.nn.functional as F"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["movie_path = './movies.csv'\n", "rating_path = './ratings.csv'"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rating_df = pd.read_csv(rating_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rating_df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lbl_user = preprocessing.LabelEncoder()\n", "lbl_movie = preprocessing.LabelEncoder()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n", "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(rating_df.userId.max())\n", "print(rating_df.movieId.max())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "load edges between users and movies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_edge_csv(df, \n", "                  src_index_col, \n", "                  dst_index_col,  \n", "                  link_index_col, \n", "                  rating_threshold=3.5):\n", "    \n", "    edge_index = None\n", "    src = [user_id for user_id in  df['userId']]\n", "    \n", "    num_users = len(df['userId'].unique())\n", "    dst = [(movie_id) for movie_id in df['movieId']]\n", "    \n", "    link_vals = df[link_index_col].values\n", "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n", "    edge_values = []\n", "    edge_index = [[], []]\n", "    for i in range(edge_attr.shape[0]):\n", "        if edge_attr[i]:\n", "            edge_index[0].append(src[i])\n", "            edge_index[1].append(dst[i])\n", "            edge_values.append(link_vals[i])\n", "                \n", "    return edge_index, edge_values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["edge_index, edge_values = load_edge_csv(\n", "    rating_df,\n", "    src_index_col='userId',\n", "    dst_index_col='movieId',\n", "    link_index_col='rating',\n", "    rating_threshold=1 \n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["edge_index = torch.LongTensor(edge_index) \n", "edge_values = torch.tensor(edge_values)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(edge_index)\n", "print(edge_index.size())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(edge_values)\n", "print(edge_values.size())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_users = len(rating_df['userId'].unique())\n", "num_movies = len(rating_df['movieId'].unique())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"num_users {num_users}, num_movies {num_movies}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index, input_edge_values):\n", "    R = torch.zeros((num_users, num_movies))\n", "    for i in range(len(input_edge_index[0])):\n", "        row_idx = input_edge_index[0][i]\n", "        col_idx = input_edge_index[1][i]\n", "        R[row_idx][col_idx] = input_edge_values[i] \n", "    R_transpose = torch.transpose(R, 0, 1)\n", "    \n", "    \n", "    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n", "    adj_mat[: num_users, num_users :] = R.clone()\n", "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n", "    \n", "    adj_mat_coo = adj_mat.to_sparse_coo()\n", "    adj_mat_coo_indices = adj_mat_coo.indices()\n", "    adj_mat_coo_values = adj_mat_coo.values()\n", "    return adj_mat_coo_indices, adj_mat_coo_values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index, input_edge_values):    \n", "    row_indices, col_indices = input_edge_index\n", "    user_movie_mask = (row_indices < num_users) & (col_indices >= num_users)\n", "    \n", "    r_mat_edge_index = torch.stack([row_indices[user_movie_mask], col_indices[user_movie_mask] - num_users])\n", "    r_mat_edge_values = input_edge_values[user_movie_mask]\n", "    return r_mat_edge_index, r_mat_edge_values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["num_interactions = edge_index.shape[1]\n", "all_indices = [i for i in range(num_interactions)]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_indices, test_indices = train_test_split(all_indices, \n", "                                               test_size=0.2, \n", "                                               random_state=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["val_indices, test_indices = train_test_split(test_indices, \n", "                                             test_size=0.5, \n", "                                             random_state=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_edge_index = edge_index[:, train_indices]\n", "train_edge_value = edge_values[train_indices]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["val_edge_index = edge_index[:, val_indices]\n", "val_edge_value = edge_values[val_indices]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["test_edge_index = edge_index[:, test_indices]\n", "test_edge_value = edge_values[test_indices]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n", "print(f\"train_edge_index {train_edge_index}\")\n", "print((num_users + num_movies))\n", "print(torch.unique(train_edge_index[0]).size())\n", "print(torch.unique(train_edge_index[1]).size())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(test_edge_value)\n", "print(test_edge_value.size())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_edge_index, train_edge_values  = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index, train_edge_value)\n", "val_edge_index, val_edge_values = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index, val_edge_value)\n", "test_edge_index, test_edge_values = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index, test_edge_value)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(train_edge_index)\n", "print(train_edge_index.size())\n", "print(val_edge_index)\n", "print(val_edge_index.size())\n", "print(test_edge_index)\n", "print(test_edge_index.size())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"\\n train_edge_values: \\n {train_edge_values} \\n {train_edge_values.size()}\")\n", "print(f\"\\n val_edge_values: \\n {val_edge_values} \\n {val_edge_values.size()}\")\n", "print(f\"\\n test_edge_values: \\n {test_edge_values} \\n {test_edge_values.size()}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class LightGCN(MessagePassing):\n", "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False, dropout_rate=0.1):\n", "        super().__init__()\n", "        self.dropout_rate = dropout_rate\n", "        self.num_users = num_users\n", "        self.num_items = num_items\n", "        self.embedding_dim = embedding_dim\n", "        self.K = K\n", "        self.add_self_loops = add_self_loops\n", "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) \n", "        \n", "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) \n", "        nn.init.normal_(self.users_emb.weight, std=0.1)\n", "        nn.init.normal_(self.items_emb.weight, std=0.1)\n", "        \n", "        self.out = nn.Linear(embedding_dim + embedding_dim, 1)\n", "        self.relu = nn.ReLU()\n", "    def forward(self, edge_index: Tensor, edge_values: Tensor):\n", "        \n", "        edge_index_norm = gcn_norm(edge_index=edge_index, add_self_loops=self.add_self_loops)\n", "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) \n", "        embs = [emb_0] \n", "        emb_k = emb_0 \n", "        \n", "        for i in range(self.K):\n", "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n", "            embs.append(emb_k)\n", "            \n", "        embs = torch.stack(embs, dim=1)\n", "        \n", "        emb_final = torch.mean(embs, dim=1)\n", "        \n", "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        r_mat_edge_index, _ = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index, edge_values)\n", "        \n", "        src, dest =  r_mat_edge_index[0], r_mat_edge_index[1]\n", "        \n", "        user_embeds = users_emb_final[src]\n", "        item_embeds = items_emb_final[dest]\n", "        \n", "        output = torch.cat([user_embeds, item_embeds], dim=1)\n", "        \n", "        output = self.out(output)\n", "        return output\n", "    \n", "    def message(self, x_j, norm):\n", "        return norm.view(-1, 1) * x_j"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["layers = 3 "]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = LightGCN(num_users=num_users, \n", "                 num_items=num_movies, \n", "                 K=layers)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "define constants"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ITERATIONS = 10000\n", "EPOCHS = 5"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BATCH_SIZE = 32"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LR = 1e-3\n", "ITERS_PER_EVAL = 1000\n", "ITERS_PER_LR_DECAY = 200\n", "K = 10\n", "LAMBDA = 1e-6"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"BATCH_SIZE {BATCH_SIZE}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "print(f\"Using device {device}.\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = model.to(device)\n", "model.train()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=0.01)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loss_func = nn.MSELoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_recall_at_k(input_edge_index, \n", "                     input_edge_values, \n", "                     pred_ratings, \n", "                     k=10, \n", "                     threshold=3.5):\n", "    with torch.no_grad():\n", "        user_item_rating_list = defaultdict(list)\n", "        for i in range(len(input_edge_index[0])):\n", "            src = input_edge_index[0][i].item()\n", "            dest = input_edge_index[1][i].item()\n", "            true_rating = input_edge_values[i].item()\n", "            pred_rating = pred_ratings[i].item()\n", "            user_item_rating_list[src].append((pred_rating, true_rating))\n", "        recalls = dict()\n", "        precisions = dict()\n", "        for user_id, user_ratings in user_item_rating_list.items():\n", "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n", "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n", "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n", "            \n", "            n_rel_and_rec_k = sum(\n", "                ((true_r >= threshold) and (est >= threshold))\n", "                for (est, true_r) in user_ratings[:k]\n", "            )\n", "            precisions[user_id] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n", "            recalls[user_id] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n", "        overall_recall = sum(rec for rec in recalls.values()) / len(recalls)\n", "        overall_precision = sum(prec for prec in precisions.values()) / len(precisions)\n", "        return overall_recall, overall_precision\n", "    "]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import roc_auc_score\n", "from sklearn.metrics import ndcg_score\n", "from collections import defaultdict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_auc_and_ndcg(input_edge_index, \n", "                     input_edge_values, \n", "                     pred_ratings, \n", "                     k=10, \n", "                     threshold=3.5):\n", "    with torch.no_grad():\n", "        user_item_rating_list = defaultdict(list)\n", "        y_true = []\n", "        y_scores = []\n", "        for i in range(len(input_edge_index[0])):\n", "            src = input_edge_index[0][i].item()\n", "            dest = input_edge_index[1][i].item()\n", "            true_rating = input_edge_values[i].item()\n", "            pred_rating = pred_ratings[i].item()\n", "            user_item_rating_list[src].append((pred_rating, true_rating))\n\n", "            # Convert true ratings to binary (0 or 1) based on the threshold\n", "            binary_true_rating = 1 if true_rating >= threshold else 0\n", "            y_true.append(binary_true_rating)\n", "            y_scores.append(pred_rating)\n\n", "        # Calculate AUC\n", "        auc = roc_auc_score(y_true, y_scores)\n\n", "        # Calculate NDCG\n", "        y_true_ndcg = np.array([y_true])  # Convert to a 2D array\n", "        y_scores_ndcg = np.array([y_scores])  # Convert to a 2D array\n", "        computed_ndcg = ndcg_score(y_true_ndcg, y_scores_ndcg, k=k)\n", "        return auc, computed_ndcg"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r_mat_train_edge_index, r_mat_train_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(train_edge_index, train_edge_values)\n", "r_mat_val_edge_index, r_mat_val_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(val_edge_index, val_edge_values)\n", "r_mat_test_edge_index, r_mat_test_edge_values = convert_adj_mat_edge_index_to_r_mat_edge_index(test_edge_index, test_edge_values)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["r_mat_train_edge_index = r_mat_train_edge_index.to(device)\n", "r_mat_train_edge_values = r_mat_train_edge_values.to(device)\n", "r_mat_val_edge_index = r_mat_val_edge_index.to(device)\n", "r_mat_val_edge_values = r_mat_val_edge_values.to(device)\n", "r_mat_test_edge_index = r_mat_test_edge_index.to(device)\n", "r_mat_test_edge_values = r_mat_test_edge_values.to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["edge_index = edge_index.to(device)\n", "edge_values = edge_values.to(device)\n", "train_edge_index = train_edge_index.to(device)\n", "train_edge_values = train_edge_values.to(device)\n", "val_edge_index = val_edge_index.to(device)\n", "val_edge_values = val_edge_values.to(device)\n", "test_edge_index = test_edge_index.to(device)\n", "test_edge_values = test_edge_values.to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_losses = []\n", "val_losses = []\n", "val_recall_at_ks = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for _ in range(EPOCHS):\n", "    for iter in tqdm(range(ITERATIONS)):\n", "        \n", "        pred_ratings = model.forward(train_edge_index, train_edge_values)\n", "        \n", "        train_loss = loss_func(pred_ratings, r_mat_train_edge_values.view(-1,1))    \n", "            \n", "        optimizer.zero_grad()\n", "        train_loss.backward()\n", "        optimizer.step()\n", "        if iter % ITERS_PER_EVAL == 0:\n", "            model.eval()\n", "            with torch.no_grad():\n", "                val_pred_ratings = model.forward(val_edge_index, val_edge_values)\n", "            \n", "                val_loss = loss_func(val_pred_ratings, r_mat_val_edge_values.view(-1,1)).sum()\n", "                \n", "                recall_at_k, precision_at_k = get_recall_at_k(r_mat_val_edge_index, \n", "                                                            r_mat_val_edge_values, \n", "                                                            val_pred_ratings, \n", "                                                            k = 20\n", "                                                            )\n", "        \n", "                    \n", "                val_recall_at_ks.append(round(recall_at_k, 5))\n", "                train_losses.append(train_loss.item())\n", "                val_losses.append(val_loss.item())\n", "            \n", "            print(f\"[Iteration {iter}/{ITERATIONS}], train_loss: {round(train_loss.item(), 7)}\")\n", "            model.train()\n", "        if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n", "            scheduler.step()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n", "plt.plot(iters, train_losses, label='train')\n", "#plt.plot(iters, val_losses, label='validation')\n", "plt.xlabel('iteration')\n", "plt.ylabel('loss')\n", "plt.title('training and validation loss curves')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["f2 = plt.figure()\n", "plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n", "plt.xlabel('iteration')\n", "plt.ylabel('recall_at_k')\n", "plt.title('recall_at_k curves')\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.eval()\n", "with torch.no_grad():\n", "    pred_ratings = model.forward(test_edge_index, test_edge_values)\n", "    recall_at_k, precision_at_k = get_recall_at_k(r_mat_test_edge_index, \n", "                                                  r_mat_test_edge_values, \n", "                                                  pred_ratings, 50)\n", "    print(f\"recall_at_k {round(recall_at_k, 5)}, precision_at_k {round(precision_at_k, 5)}\")\n", "    auc_score, ndcg_score = get_auc_and_ndcg(r_mat_test_edge_index, r_mat_test_edge_values,  pred_ratings)\n", "    print(f\"AUC: {auc_score}, NDCG: {ndcg_score}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_path = 'model_mean.pth'\n", "torch.save(model.state_dict(), model_path)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["%%<br>\n", "model_path = 'model_mean.pth'<br>\n", "model.load_state_dict(torch.load(model_path))"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}